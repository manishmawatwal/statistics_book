{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 51,  92,  14,  71,  60,  20,  82,  86,  74,  74,  87,  99,  23,\n",
       "         2,  21,  52,   1,  87,  29,  37,   1,  63,  59,  20,  32,  75,\n",
       "        57,  21,  88,  48,  90,  58,  41,  91,  59,  79,  14,  61,  61,\n",
       "        46,  61,  50,  54,  63,   2, 100,  50,   6,  20,  72,  38,  17,\n",
       "         3,  88,  59,  13,   8,  89,  52,   1,  83,  91,  59,  70,  43,\n",
       "         7,  46,  34,  77,  80,  35,  49,   3,   1,   5,  53,   3,  53,\n",
       "        92,  62,  17,  89,  43,  33,  73,  61,  99,  13,  94,  47,  14,\n",
       "        71,  77,  86,  61,  39,  84,  79,  81,  52])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a random dataset of exam scores\n",
    "np.random.seed(42)\n",
    "exam_scores = np.random.randint(low=0, high=101, size=100)\n",
    "exam_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the overall pass rate of the entire dataset\n",
    "overall_pass_rate = np.mean(exam_scores > 60)\n",
    "overall_pass_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92,  99,  91, 100,  91,  92,  99,  94])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cherry pick a subset of data points where students performed exceptionally well\n",
    "cherry_picked_scores = exam_scores[exam_scores > 90]\n",
    "cherry_picked_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the pass rate of the cherry-picked subset\n",
    "cherry_picked_pass_rate = np.mean(cherry_picked_scores > 60)\n",
    "cherry_picked_pass_rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the potential bias introduced by cherry picking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall pass rate of the entire dataset: 0.42\n",
      "Pass rate of the cherry-picked subset: 1.0\n"
     ]
    }
   ],
   "source": [
    "# print the results\n",
    "print(\"Overall pass rate of the entire dataset:\", overall_pass_rate)\n",
    "print(\"Pass rate of the cherry-picked subset:\", cherry_picked_pass_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
